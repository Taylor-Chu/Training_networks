{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/sc004/sc004/tc1213/miniconda3/envs/pl2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "usage: ipykernel_launcher.py [-h] [--folder_out FOLDER_OUT]\n",
      "                             [--checkpoint_path CHECKPOINT_PATH]\n",
      "                             [--architecture ARCHITECTURE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"71336c65-7570-428c-af51-51c6fdb6c62c\" --shell=9007 --transport=\"tcp\" --iopub=9009\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/sc004/sc004/tc1213/miniconda3/envs/pl2/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3405: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from lightning_denoiser import GradMatch\n",
    "from data_module import DataModule\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "# from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "import os\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from models.model_to_onnx import convert_model\n",
    "from argparse import ArgumentParser\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS']='0'\n",
    "torch.cuda.empty_cache()\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('--name', type=str, default='test')\n",
    "parser.add_argument('--log_folder', type=str, default='logs')\n",
    "parser.add_argument('--save_images', dest='save_images', action='store_true')\n",
    "parser.set_defaults(save_images=False)\n",
    "\n",
    "# MODEL args\n",
    "parser = GradMatch.add_model_specific_args(parser)\n",
    "# DATA args\n",
    "parser = DataModule.add_data_specific_args(parser)\n",
    "# OPTIM args\n",
    "parser = GradMatch.add_optim_specific_args(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS']='0'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    # PROGRAM args\n",
    "    torch.cuda.empty_cache()\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--name', type=str, default='test')\n",
    "    parser.add_argument('--log_folder', type=str, default='logs')\n",
    "    parser.add_argument('--save_images', dest='save_images', action='store_true')\n",
    "    parser.set_defaults(save_images=False)\n",
    "\n",
    "    # MODEL args\n",
    "    parser = GradMatch.add_model_specific_args(parser)\n",
    "    # DATA args\n",
    "    parser = DataModule.add_data_specific_args(parser)\n",
    "    # OPTIM args\n",
    "    parser = GradMatch.add_optim_specific_args(parser)\n",
    "\n",
    "    hparams = parser.parse_args()\n",
    "\n",
    "    refresh_rate = 144\n",
    "\n",
    "    random.seed(hparams.seed)\n",
    "    torch.manual_seed(hparams.seed)\n",
    "    \n",
    "    if not os.path.exists(hparams.log_folder):\n",
    "        os.makedirs(hparams.log_folder, exist_ok=True)\n",
    "    log_path = hparams.log_folder + '/' + hparams.name\n",
    "    if not os.path.exists(log_path):\n",
    "        os.makedirs(log_path, exist_ok=True)\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(log_path)\n",
    "\n",
    "    model = GradMatch(hparams)\n",
    "    dm = DataModule(hparams)\n",
    "\n",
    "    if hparams.pretrained_checkpoint is not None:\n",
    "        checkpoint = torch.load(hparams.pretrained_checkpoint)\n",
    "        print('Loaded pretrained network from {}.'.format(hparams.pretrained_checkpoint))\n",
    "        model.load_state_dict(checkpoint['state_dict'],strict=False)\n",
    "\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val/3_val_loss',\n",
    "        min_delta=1e-8,\n",
    "        patience=hparams.early_stopping_patiente,\n",
    "        verbose=True,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "    if hparams.jacobian_loss_weight > 0:\n",
    "        max_epochs = 400\n",
    "        hparams.scheduler_milestones = 300\n",
    "    else:\n",
    "        max_epochs = 800\n",
    "\n",
    "    # removing log_gpu_memory, if needed use DeviceStatsMonitor callback\n",
    "\n",
    "    save_checkpoint = ModelCheckpoint(\n",
    "        filename=\"best_{epoch}-{step}\",\n",
    "        monitor=\"val/3_val_loss\",\n",
    "        save_top_k=1,\n",
    "        mode=\"min\"\n",
    "    )\n",
    "\n",
    "    # save_epoch_checkpoint = ModelCheckpoint(\n",
    "    #     filename=\"{epoch}-{step}\",\n",
    "    #     monitor=\"period\",\n",
    "    #     save_top_k=-50\n",
    "    # )\n",
    "\n",
    "    trainer = pl.Trainer.from_argparse_args(hparams, logger=tb_logger, gpus=-1,\n",
    "                                            check_val_every_n_epoch=50,\n",
    "                                            gradient_clip_val=hparams.gradient_clip_val,\n",
    "                                            max_epochs=max_epochs, precision=16,\n",
    "                                            callbacks=[lr_monitor,save_checkpoint], \n",
    "                                            # accelerator = 'gpu',\n",
    "                                            strategy='ddp',\n",
    "                                            enable_progress_bar = False)\n",
    "    trainer.fit(model, dm)\n",
    "    final_ckpt_pth = os.path.join(log_path,'final.ckpt')\n",
    "    trainer.save_checkpoint(final_ckpt_pth)\n",
    "    \n",
    "    # save_pth = os.path.join('/work/sc004/sc004/tc1213/trained_networks',hparams.dataset_name, hparams.model_name) +'/seed'+str(hparams.seed)\n",
    "    # save_name = hparams.model_name + '_' + hparams.dataset_name + '_' + str(hparams.sigma) + '_' + str(hparams.dr) + '_' + str(hparams.seed) + '.onnx'\n",
    "    # convert_model(hparams.model_name,\n",
    "    #                 os.path.join(save_pth, save_name),\n",
    "    #                 final_ckpt_pth)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pl2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6bb2915baab67a227d071999a87efe888fbfd627c4d765339da1a10146690c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
